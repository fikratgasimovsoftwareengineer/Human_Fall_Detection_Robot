#include <map>
#include <iostream>
#include <string>
#include <chrono>
#include <NvInfer.h>
#include <NvInferPlugin.h>
#include <l2norm_helper.h>
#include <opencv2/highgui.hpp>
#include "faceNet.h"
#include "videoStreamer.h"
#include "network.h"
#include "mtcnn.h"

#include "json.hpp"
#include "client_socket.h"

using json = nlohmann::json;
// Uncomment to print timings in milliseconds
// #define LOG_TIMES

using namespace nvinfer1;
using namespace nvuffparser;


int main()
{
    Logger gLogger = Logger();
    // Register default TRT plugins (e.g. LRelu_TRT)
    if (!initLibNvInferPlugins(&gLogger, "")) { return 1; }

    // USER DEFINED VALUES
    const string uffFile="../facenetModels/facenet.uff";
    const string engineFile="../facenetModels/facenet.engine";
    DataType dtype = DataType::kHALF;
    //DataType dtype = DataType::kFLOAT;
    bool serializeEngine = true;
    int batchSize = 1;
    int nbFrames = 0;
    int videoFrameWidth = 640;
    int videoFrameHeight = 480;
    int maxFacesPerScene = 10;
    float knownPersonThreshold = 0.9;
    bool isCSICam = false; //false for USB cam
    //AP
    int port = 5000;
    string hostname = "127.0.0.1";

    //AP:end 

    // init facenet
    FaceNetClassifier faceNet = FaceNetClassifier(gLogger, dtype, uffFile, engineFile, batchSize, serializeEngine,
            knownPersonThreshold, maxFacesPerScene, videoFrameWidth, videoFrameHeight);

    // init opencv stuff
    VideoStreamer videoStreamer = VideoStreamer(0, videoFrameWidth, videoFrameHeight, 60, isCSICam);
    cv::Mat frame;

    // init mtCNN
    mtcnn mtCNN(videoFrameHeight, videoFrameWidth);

    //init Bbox and allocate memory for "maxFacesPerScene" faces per scene
    std::vector<struct Bbox> outputBbox;
    outputBbox.reserve(maxFacesPerScene);

    // get embeddings of known faces and save face names in a vector
    std::vector<std::string> persons;
    std::vector<struct Paths> paths;
    cv::Mat image;
    getFilePaths("../imgs", paths);
    for(int i=0; i < paths.size(); i++) {
        loadInputImage(paths[i].absPath, image, videoFrameWidth, videoFrameHeight);
        outputBbox = mtCNN.findFace(image);
        std::size_t index = paths[i].fileName.find_last_of(".");
        std::string rawName = paths[i].fileName.substr(0,index);
        faceNet.forwardAddFace(image, outputBbox, rawName);
        faceNet.resetVariables();
	persons.push_back(rawName);
    }
    outputBbox.clear();


    //initialize counters and timers (in seconds), and declare thresholds
    int m_counts_th = 5;
    std::vector<int> m_counts(persons.size(),0); 
    std::vector<int> m_time_buffer(persons.size(),5); 
    std::vector<int> m_alarm_interval(persons.size(),20); 
    std::vector<int> m_start_count_time(persons.size(),0); 
    std::vector<int> m_alarm_time(persons.size(),0); 
    std::vector<int> m_last_count_time(persons.size(),0); 
    int m_time_delay = 10;


    //create TCP client connect to server
    tcp_client c;
    c.conn(hostname, port);

    // loop over frames with inference
    auto globalTimeStart = chrono::steady_clock::now();
    while (true) {
        videoStreamer.getFrame(frame);
        if (frame.empty()) {
            std::cout << "Empty frame! Exiting...\n Try restarting nvargus-daemon by "
                         "doing: sudo systemctl restart nvargus-daemon" << std::endl;
            break;
        }
	auto startMTCNN = chrono::steady_clock::now();
        outputBbox = mtCNN.findFace(frame);
        auto endMTCNN = chrono::steady_clock::now();
        auto startForward = chrono::steady_clock::now();
        faceNet.forward(frame, outputBbox);
        auto endForward = chrono::steady_clock::now();
        auto startFeatM = chrono::steady_clock::now();
        std::map<std::string, int> personRec = faceNet.featureMatching(frame);
        auto endFeatM = chrono::steady_clock::now();
        faceNet.resetVariables();
      
	auto frame_time = std::chrono::system_clock::now();
	int m_frame_time = int(std::chrono::duration_cast<chrono::seconds>(frame_time.time_since_epoch()).count()); 
     
        //threshold system to send alarms     
	for(auto& it : personRec)
	{
	   if (personRec.size() == persons.size()) 
	   {	
               for(int p=0; p < persons.size(); p++) 
	       {
                  if (persons[p] == it.first && it.second==1)
                  {
		      //person seen for the first time
		      if (m_counts[p]==0)
	              {
                         m_counts[p] = 1;
			 m_start_count_time[p] = m_frame_time;
			 m_last_count_time[p] = m_frame_time;
	              }		      
		      //increment counters
		      if (m_counts[p]>0 && ((m_frame_time - m_start_count_time[p]) < m_time_buffer[p]) && ((m_frame_time - m_last_count_time[p]) < m_time_delay))
	              {
                         m_counts[p]++;
                         m_last_count_time[p] = m_frame_time;
		      }
		      if (m_counts[p]<m_counts_th && (((m_frame_time-m_start_count_time[p])>=m_time_buffer[p]) || ((m_frame_time-m_last_count_time[p])>m_time_delay)))
		      {
		         m_counts[p] = 1;
                         m_start_count_time[p] = m_frame_time;
                         m_last_count_time[p] = m_frame_time;
		      }
		      if (m_counts[p]>=m_counts_th && (m_frame_time-m_last_count_time[p])>m_time_delay)
	              {
			 m_counts[p] = 1;
			 m_start_count_time[p] = m_frame_time;
                         m_last_count_time[p] = m_frame_time;     
		      }
		      if (m_counts[p]>=m_counts_th && ((m_frame_time-m_last_count_time[p])<m_time_delay) && ((m_frame_time-m_start_count_time[p])>=m_time_buffer[p]) && ((m_frame_time-m_alarm_time[p]) > m_alarm_interval[p]))
		      {
                           //send an alarm json and reset counters
                           time_t current_time = time(0);
                           json fr_output =
                           {
                              {"Person", it.first},
                              {"Timestamp", ctime(&current_time)},
                           };
                           //send json
                           string fr_output_s = fr_output.dump();
                           c.send_data(fr_output_s+"\n");
                           //receive a reply from server
                           std::cout << "Received: " << c.receive(1024) << std::endl;

 
  		 	   m_counts[p] = 0;
		           m_alarm_time[p] = m_frame_time;	
		      }	      
		  }
	       }     
	   } 	   
        }

	//cv::Mat flipped;
	//cv::flip(frame, flipped, 0);
        //cv::imshow("VideoSource", flipped);
        cv::imshow("VideoSource", frame);
        nbFrames++;
        outputBbox.clear();
        frame.release();

        char keyboard = cv::waitKey(1);
        if (keyboard == 'q' || keyboard == 27)
            break;
        else if(keyboard == 'n') {
            auto dTimeStart = chrono::steady_clock::now();
            videoStreamer.getFrame(frame);
	    //cv::Mat flipped_frame;
	    //cv::flip(frame, flipped_frame, 0);
            //outputBbox = mtCNN.findFace(flipped_frame);
            outputBbox = mtCNN.findFace(frame);
            //cv::imshow("VideoSource", flipped_frame);
            cv::imshow("VideoSource", frame);
            faceNet.addNewFace(frame, outputBbox);
            //faceNet.addNewFace(flipped_frame, outputBbox);
            auto dTimeEnd = chrono::steady_clock::now();
            globalTimeStart += (dTimeEnd - dTimeStart);
        }

        #ifdef LOG_TIMES
        std::cout << "mtCNN took " << std::chrono::duration_cast<chrono::milliseconds>(endMTCNN - startMTCNN).count() << "ms\n";
        std::cout << "Forward took " << std::chrono::duration_cast<chrono::milliseconds>(endForward - startForward).count() << "ms\n";
        std::cout << "Feature matching took " << std::chrono::duration_cast<chrono::milliseconds>(endFeatM - startFeatM).count() << "ms\n\n";
        #endif  // LOG_TIMES
    }
    auto globalTimeEnd = chrono::steady_clock::now();
    cv::destroyAllWindows();
    videoStreamer.release();
    auto milliseconds = chrono::duration_cast<chrono::milliseconds>(globalTimeEnd-globalTimeStart).count();
    double seconds = double(milliseconds)/1000.;
    double fps = nbFrames/seconds;

    std::cout << "Counted " << nbFrames << " frames in " << double(milliseconds)/1000. << " seconds!" <<
              " This equals " << fps << "fps.\n";

    return 0;
}

